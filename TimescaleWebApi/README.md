# Документация проекта TimescaleApi

## Структура проекта
Решение организовано в четыре основных проекта:
- **TimescaleApi.Domain**: Содержит сущности (`Value`, `Result`) и интерфейсы (`IValueRepository`, `IResultRepository`) для определения доменной модели и контракта доступа к данным.
- **TimescaleApi.Application**: Содержит `ValueService`, который инкапсулирует бизнес-логику обработки CSV-данных и генерации статистических результатов.
- **TimescaleApi.Infrastructure**: Реализует логику персистенции с использованием `AppDbContext` (Entity Framework Core) и классов репозиториев (`ValueRepository`, `ResultRepository`).
- **TimescaleApi.Web**: Обеспечивает API-контроллеры (`ValuesController`, `ResultsController`) и конфигурацию веб-приложения.


## Подробности реализации

### Обработка данных и работа с CSV
- **Подход**: Метод `ValueService.ProcessCsvAsync` использует `CsvHelper` для парсинга CSV-файлов с разделителем точкой с запятой (`;`). Каждая строка проверяется на соответствие даты (между 2000-01-01 и текущей датой) и положительные значения `ExecutionTime` и `MeasuredValue`.
- **Обоснование**: Валидация обеспечивает целостность данных, а использование разделителя `;` учитывает разнообразие источников ввода. Ограничение количества строк (от 1 до 10 000) предотвращает проблемы с производительностью при обработке больших файлов.
- **Решение**: При обнаружении недопустимых данных выбрасываются исключения, а статистика (например, среднее, медиана) вычисляется непосредственно в памяти перед сохранением в базу данных.

### Обработка транзакций
- **Подход**: Транзакции управляются с использованием `IDbContextTransaction` в `ValueService.ProcessCsvAsync`. Процесс включает удаление существующих данных с тем же `FileName`, добавление новых записей `Value`, удаление старого `Result` и добавление нового `Result`, всё в рамках одной транзакции.
- **Обоснование**: Атомарность критически важна для обеспечения согласованности данных. Если какая-либо операция завершится с ошибкой (например, из-за нарушения ограничений базы данных), транзакция откатывается, предотвращая частичные обновления, которые могут оставить базу в несогласованном состоянии.
- **Решение**: Метод `BeginTransactionAsync` вызывается из репозитория, а `CommitAsync` выполняется только при успешном завершении всех операций. Блок `try-catch` гарантирует вызов `RollbackAsync` в случае сбоя, обеспечивая надёжность.

### Репозитории и доступ к данным
- **Подход**: Репозитории (`ValueRepository`, `ResultRepository`) реализуют интерфейсы, определённые в слое домена, используя Entity Framework Core для взаимодействия с PostgreSQL.
- **Обоснование**: Это декуплирует слой доступа к данным от бизнес-логики, позволяя в будущем заменить базу данных на другую систему. Индексы по `FileName` в `AppDbContext` оптимизируют производительность запросов для данных временных рядов.
- **Решение**: Методы, такие как `GetLast10ByFileNameAsync`, используют `Take(10)` с `OrderBy` для эффективного получения последних данных, а `GetFilteredResultsAsync` строит динамические LINQ-запросы на основе необязательных параметров фильтрации.

### Конечные точки API
- **Подход**: `ValuesController` обрабатывает загрузку CSV и получение последних 10 значений, а `ResultsController` поддерживает запросы отфильтрованных результатов.
- **Обоснование**: RESTful конечные точки предоставляют понятный интерфейс для клиентов. 
- **Решение**: Обработка ошибок возвращает соответствующие коды состояния HTTP (например, `400 Bad Request` для недопустимых файлов, `404 Not Found` при отсутствии результатов), улучшая пользовательский опыт.

### Условия и вызовы
- **Ограничение количества строк (1-10 000)**: Установлено для предотвращения перегрузки памяти. Решано путём выбрасывания `ArgumentException` при превышении лимита.
- **Валидация даты**: Обеспечивает актуальность данных, ограничивая даты после 2000 года. Обрабатывается с помощью `DateTime.Parse` и проверок сравнения.
- **Сбои транзакций**: Решаются с помощью логики отката, протестированной на симулированных сбоях.
- **Производительность**: Индексы и эффективные LINQ-запросы минимизируют узкие места, хотя большие наборы данных могут потребовать дальнейшей оптимизации (например, пакетной обработки).
